(1.) Data Collection and Preprocessing*
#import the required libraries

import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
from time import sleep
from random import randint
import matplotlib.pyplot as plt

# **IMDB Data Scrapping**
IMDB website data has been scrapped by using the below code.

**Difficulties:**

We faced difficulties in
Cleansing Year, Genre, Certification, Rating, Description, top_250

We were able to resolve the issues by the following code below except for the top_250 column
# collect the first 200 movies

pages = np.arange(1,1000,50)
temp=[]
for page in pages:
  page =requests.get("https://www.imdb.com/search/title/?groups=top_1000&sort=user_rating,desc&start=" +str(page) +"&ref_=adv_nxt")
  soup = BeautifulSoup(page.text,'html.parser')
  movie_data = soup.find_all('div',class_='lister-item mode-advanced')

  sleep(randint(2,8))

  for item in movie_data:
    year =item.find('span', class_='lister-item-year text-muted unbold').text.strip()
    year_clean=str(year).replace('(','').replace(')','').replace('I','').replace(' ','')
    rating = item.find('strong').text.replace('\n','')
    time= item.find('span',class_='runtime').text.replace('\n','').replace('min','')
    genre= item.find('span',class_='genre').text.replace('\n','')
    certification=item.find('span', class_='certificate').text if item.find('span',class_='certificate') != None else np.nan
    meta=int(item.find('span', class_='metascore favorable').text.strip()) if item.find('span',class_='metascore favorable') != None else np.nan
    descr=item.find_all('p',class_='text-muted')[1].get_text().replace('\n','')
    title = item.find_all('a')[1].get_text().replace('\n','')
    dir = item.find_all('p')[2].find_all('a')[0].get_text().replace('\n','')
    votes=item.find('span', {"name":"nv"}).text.strip().replace(',','')
    a=item.find_all('span',attrs={'name':'nv'})
    gross=float(a[1].text.replace("$", "").replace("M", ""))*1000000 if len(a) > 2 else np.nan
    top_250=(item.find('p',class_='sort-num_votes-visible').find_all('span'))[7:8]

    temp.append([year_clean,rating,time,genre,certification,meta,descr,title,dir,votes,gross,top_250])




df = pd.DataFrame(temp, columns=['Year', 'Rating', 'Span(mins)', 'Genre', 'Certificate', 'Meta_Score', 'Description', 'Title', 'Director', 'Votes', 'Gross', 'Top_250'])
df['Title'] = df['Title'].str.upper()




# Writing the CSV

We have saved the scrapped data into our local directory.
df.to_csv(r'C:\Documents\dataframe.csv')
(2.) EDA

You must use some plots when answering some of the questions in the sections.
**What are the most popular movies in terms of Votes?**

We have converted the Votes column into integer and sorted them in  descending order. Then we have printed the first 10 rows of our DataFrame.


df['Votes']=df['Votes'].astype(int)
v_df = df.sort_values(by = ['Votes'], ascending=False)
v_df.head(10)
**Which are the highest (top 3) and lowest (bottom 5) rated movies in terms of Score?**

We have sorted Meta_Score column in descending order. Then we have printed the first 3 rows and last 5 rows of our DataFrame to show top 3 and bottom 5 rated movies.
s_df = df.sort_values(by = ['Meta_Score'], ascending=False)
print('The highest 3 Meta Scores are: ')
display(s_df.head(3))
m_df = df.sort_values(by = ['Meta_Score'], ascending=False, na_position='first')
print("The lowest 5 Meta Scores are: ")
display(m_df.tail(5))
**What are the most popular genres (top 5)?**

We grouped Top_Genre column and counted the Number of times each Genre is appearing based on that we have printed first 5 rows to show the most popular Genre of our DataFrame.
Top_Genres = df['Genre'].value_counts()
print(Top_Genres.head(5))
**Who are the most popular directors in terms of number of Votes?**

We grouped Director column and Sum the Number of Votes for each Director then sorted the values in descending order and printed the top 10 Director based on Votes.
Popular_Directors = df.groupby('Director')['Votes'].sum().sort_values(ascending=False)
print(Popular_Directors.head(10))
**Which movies (top 5) that have the longest Runtimes (minutes)?**

We converted Span(mins) column into integer and then we sorted our DataFrame by Span in descending order.
df['Span(mins)']=df['Span(mins)'].astype(int)
r_df = df.sort_values(by = ['Span(mins)'], ascending=False)
r_df[['Title','Span(mins)']].head(5)
**Which movies (top 5) that have the shortest Runtimes (minutes)?**

We converted Span(mins) column into integer and then we sorted our DataFrame by Span in descending order and printed the last 5 rows with title and Span(mins) Column.
r_df = df.sort_values(by = ['Span(mins)'], ascending=False)
r_df[['Title','Span(mins)']].tail(5)
**Which decade had the movies with the shortest Runtimes?**

We grouped our DataFrame by  Year column and calulated the mean of Span(mins) for each Year.
Decade_Shortest = df.groupby('Year')['Span(mins)'].mean().sort_values()
Decade_Shortest.head(5)
**Show the distribution of movies over time.**

We converted Year column into integer and then we created a new Dataframe Movies Distribution which has Movies Count group by Year of the Original Dataset and then plotted the movies Distribution.
df['Year']=df['Year'].astype(int)

movie_distribution= df.groupby('Year').size().to_frame('MoviesCount')

figure1, ax = plt.subplots()

ax.bar(movie_distribution.index,
        movie_distribution['MoviesCount'],
        color="blue")
ax.set_xlabel("Year", fontsize = 14)
ax.set_ylabel("Movies Count",
              fontsize=14)
plt.title('Distribution of Movies Over a period of Time', fontsize=16)
plt.show()
**Show the distribution of Scores and film critic ratings (Metascore) on a single chart.**

We have converted the Values in Rating Column and then we plotted the Meta_Score and Rating columns by using sns plots.
fig = sns.kdeplot(df['Rating']*10, shade=True, color="y")
fig = sns.kdeplot(df['Meta_Score'], shade=True, color="r")



plt.show()

**Create a chart to display the genres of movies (top 5) that have the longest duration (minutes).**

We sorted our DataFrame by Span(mins) in Descending Order then we plotted the Genre and Span(mins) values for the first 5 rows.

 df=df.sort_values(['Span(mins)'],ascending=False)
af=df[['Genre','Span(mins)']].head(5)
af.plot(kind="bar",x="Genre")
**Create 3 additional analyses or your choice that you believe provide more insight into the data.**

**1.Count of Movies for Different Rating**

We have created a histo Plot by giving Rating column in X-axis which gave us the frequency of each Rating.


sns.histplot(data=df, x = "Rating")
**Meta_Score with Gross**

We have created a Scatter Plot for Gross and Meta_Score to see the relationship between Gross and Meta_Score. Gross is not depending on the Meta_Score. If Gross is low Meta_Score might be High or Low.
df.plot(kind='scatter', x='Gross', y='Meta_Score')
**Frequency of Meta_Score**

We have plot a hist plot by dropping the NA's from Meta_Score column to analyze which Meta_Score was frequent among the movies.
df['Meta_Score'] = df['Meta_Score'].dropna()
sns.histplot(df['Meta_Score'])
# (3.) Bivariate Analysis

You must use two different types of plots to answer the questions in this section.
**Is there a  relationship between revenue and IMDB Score?**

We have plot a box plot and Scatter plot to see the relationship between Gross and Rating. From our Analysis if Gross is High Rating may be High or Low.
import pandas as pd
import matplotlib.pyplot as mp
import seaborn as sns
# data = pd.read_csv("/content/C:\Documents\dataframe.csv")

# df = pd.DataFrame(data,columns)
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5))
# # plot the dataframe
#df.boxplot(by="Rating", column=["Gross"])
sns.boxplot(x="Rating",y="Gross",data=df,ax=ax[0])
#sns.stripplot(x="Rating",y="Gross",data=df,ax=ax[1])
sns.scatterplot(x="Rating",y="Gross",data=df,ax=ax[1])
# # print bar graph
# mp.show()

**Create a chart and show the relationship between the Metascore and the IMDB score.**

We have plot a box plot and Scatter plot to see the relationship between Meta_Score and Rating. From our Analysis if Meta_Score is High Rating may be High or Low.

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5))

sns.boxplot(x="Rating",y="Meta_Score",data=df,ax=ax[0])

sns.scatterplot(x="Rating",y="Meta_Score",data=df,ax=ax[1])
**Create 2 more charts if your choice that show the relationships between any variables of your choice.**

(1) We have plot a box plot and Scatter plot for Rating and Span(mins) and to see the relationship between Span(mins) and Rating. From our Analysis if Span(mins) is high Rating maybe High or Low.

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5))

sns.boxplot(x="Rating",y="Span(mins)",data=df,ax=ax[0])

sns.scatterplot(y="Span(mins)",x="Rating",data=df,ax=ax[1])


**Count of Movies with certificate**

We have plotted a barplot Movies Count and the Certificate.
From our Analysis most of the movies are R-Certified.
movie_distribution= df.groupby('Certificate').size().to_frame('MoviesCount')

figsize=(20,16)

movie_distribution.plot(kind="bar")
# (4.) Text Analysis

**Excluding stopwords, what are the 10 most popular words used in movie titles?**

We have imported nltk package into Google Colab to get Stopwords, word_tokenize and Counter Function.We have converted each title to lower case and removed Stopped Words from our title Column. Then we used Counter function and most_common to get the most popular words from movie title.
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')
from nltk.tokenize import word_tokenize
from collections import Counter
from nltk.corpus import stopwords
stop = stopwords.words('english')
df['title_without_stopwords'] = df['Title'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in (stop)]))
Counter(" ".join(df['title_without_stopwords']).split()).most_common(10)


**Do movies with longer descriptions generate more revenue or have higher Metascores?**

We created 2 bar plots and one correlation matrix to see if there is relationship between Gross,Meta_Score and Description Count. From our Analysis we found that the relation between those is not that significant.
df["count"] = df["Description"].apply(len)
import matplotlib.pyplot as plt
x = df['count']
y=df['Meta_Score']
plt.bar(x, y, label = "count vs score")
plt.show()
#No since a movie with higher number of words in description(>50) has low meta score (<80)

x = df['count']
y=df['Gross']
plt.bar(x, y, label = "count vs score")
plt.show()
#No since a movie with higher number of words in description(>45) has low revenue (<200000000)


import seaborn as sns
df_l=pd.DataFrame(df,columns=['count','Gross','Meta_Score'])
corre=df_l.corr()

sns.heatmap(corre)
plt.show()
print(corre)
**Installing VaderSentiment Package**
pip install vaderSentiment
**Are there differences in sentiment of the description across genres?**

We have used VaderSentiment Package to get the Sentiment Score for each description. Then we plotted sentiment score and Genre where we can see that te sentiment score is different across Genres.
import vaderSentiment
from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
sent = SentimentIntensityAnalyzer()
polarity = [round(sent.polarity_scores(i)['compound'], 2) for i in df['Description']]
df['sentiment_score'] = polarity
df

df.plot(y='sentiment_score',x='Genre')
**Create 3 word clouds using the description column: one for each of the top 3 most popular genres.**

We have used WordCloud package to generate word cloud for Description of top 3 Genres.
from wordcloud import WordCloud
from wordcloud import ImageColorGenerator
from wordcloud import STOPWORDS
import matplotlib.pyplot as plt

df_drama = df[df['Genre'].str.contains('Drama')]
text = " ".join(i.split()[1] for i in df_drama.Description)
word_cloud = WordCloud(collocations = False, background_color='White').generate(text)
plt.imshow(word_cloud, interpolation='bilinear')
plt.axis("off")
print('Word Cloud for Drama Genre:')
plt.show()

df_drama2 = df[df['Genre'].str.contains('Drama, Romance')]
text = " ".join(i.split()[1] for i in df_drama.Description)
word_cloud = WordCloud(collocations = False, background_color='White').generate(text)
plt.imshow(word_cloud, interpolation='bilinear')
plt.axis("off")
print('Word Cloud for Drama, Romance Genre:')
plt.show()

df_drama2 = df[df['Genre'].str.contains('Comedy, Drama')]
text = " ".join(i.split()[1] for i in df_drama.Description)
word_cloud = WordCloud(collocations = False, background_color='White').generate(text)
plt.imshow(word_cloud, interpolation='bilinear')
plt.axis("off")
print('Word Cloud for Comedy,Drama Genre:')
plt.show()

**Are there any interesting relationships between the text column and any of the other variables in your dataset?**

**Time span of movie vs Description length**

We have plotted a Scatter plot for Span(mins).From our Analysis the Average Span(mins) lies in between 150.
df.plot(kind="scatter",y='count',x='Span(mins)')

# (5.) Comparative Analysis
**Pick any two decades and do a comprehensive comparative analysis of movies in those two decades.**

**Your analysis must address at least 5 interesting questions. None of the questions can be those listed in the EDA section of this document.**





(1) We have plotted a Scatter plot for sentiment_score and Meta_Score.To see if the movies with high Meta_Score has positive Sentiment. There is no significant relation between Meta_Score and sentiment_score.

df.plot(kind='scatter', y='Meta_Score', x='sentiment_score' )

(2) We have plot a Scatter plot for Span(mins) and Year. From our Analysis in years 1920 to 1980 the Span(mins) is Low. Later, from 2000 - 2020 the Average Span(mins) lies in between 100-150.
df.plot(kind='scatter', y='Year', x='Span(mins)' )

(3) Here we have plot a Line chart, by considering the votes of movie and Span(mins) of movie. Movies with Span(mins) closer to 150 has the highest number of Votes.
df.plot(kind="line",x='Span(mins)',y='Votes')
(4)We have plotted a barplot Movies Count and the Certificate.
From our Analysis most of the movies are R-Certified.
movie_distribution= df.groupby('Certificate').size().to_frame('MoviesCount')

figure1, ax = plt.subplots()

ax.bar(movie_distribution.index,

        movie_distribution['MoviesCount'],

        color="blue")

ax.set_xlabel("Year", fontsize = 14)

ax.set_ylabel("Movies Count",

              fontsize=14)

plt.title('Distribution of Movies Over Certificate', fontsize=16)

plt.show()
(5)**relationship between Meta_Score and Votes**

We have plotted a barplot to show the relationship between Meta_Score and Number of Votes. Their relationship is not accurate.
import pandas as pd
import seaborn as sns
data = pd.read_csv("/content/C:\Documents\dataframe.csv")
df = pd.DataFrame(data)
sns.barplot(x=df['Meta_Score'],y=df['Votes'],color='Blue')
# (6.) Multivariate Analysis
**Create a regression model to determine which of the following variables predicts revenue**

**Number of words in a title, Number of Words in the Description,Score, Metascore, Vote and Runtime**
We have import the packages of pandas, altair, numpy, seaborn and matplotlib
import pandas as pd
import altair as alt
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
**Installation of tools package**
pip install tools
from pandas.plotting import scatter_matrix
We have count the number of words of title by using str.len() function and gave the column name as Title_Count
df['Title_Count'] = df['Title'].str.len()
df
We have count the number of words of Description by using str.len() function and gave the column name as Description_Count
df['Description_Count'] = df['Description'].str.len()
df
We have plotted a Scatter_matrix plot for Rating,Span(mins), Meta_Score,Votes.
pd.plotting.scatter_matrix(df1.loc[:, "Rating":"Votes"], diagonal="kde")
plt.tight_layout()
plt.show()
pd.plotting.scatter_matrix(df1.loc[:, "Meta_Score":"Votes"], diagonal="kde")
plt.tight_layout()
plt.show()
We have taken the Span(mins) and Meta_Score. From our Analysis Average Meta_Score is in between 8.0 to 8.3
sns.lmplot("Meta_Score", "Span(mins)", data, hue="Rating", fit_reg=False);
Here is the Regression model for Multi Variate Analysis. We have import the linear_model for sklearn and import the statsmodels.api.

From our Analysis we have done a linear regression model for Multi Variate Analysis where R-Squared Value is not the significant and the P- Value is high than the expected so this model is not relevant.
from sklearn import linear_model

import statsmodels.api as sm

df=df.dropna()

x = df[['Title_Count','Description_Count','Meta_Score','Votes','Span(mins)']]

y = df['Gross']

np.isnan(df["Title_Count"]).any(),np.isnan(df["Gross"]).any(), np.isnan(df["Description_Count"]).any(), np.isnan(df["Meta_Score"]).any(),

np.isnan(df["Votes"]).any(), np.isnan(df["Span(mins)"]).any()

regr = linear_model.LinearRegression()

regr.fit(x, y)

print('Intercept: \n', regr.intercept_)

print('Coefficients: \n', regr.coef_)

# with statsmodels

x = sm.add_constant(x)

model = sm.OLS(y, x).fit()

predictions = model.predict(x)

print_model = model.summary()

print(print_model)

